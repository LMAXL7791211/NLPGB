{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HW 2 NLP Lukyanov M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тема “Создание признакового пространства”\n",
    "\n",
    "\n",
    "Продолжим обработку данных с Твиттера. \n",
    "\n",
    "\n",
    "1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "Исключим стоп-слова с помощью stop_words='english'. \n",
    "Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n",
    " \n",
    " \n",
    "2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "Исключим стоп-слова с помощью stop_words='english'.\n",
    "Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names().\n",
    " \n",
    " \n",
    "3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре, составьте таблицу метод векторизации и скор который вы получили (в методах векторизации по изменяйте параметры что бы добиться лучшего скора) обратите внимание как падает/растёт скор при уменьшении количества фичей, и изменении параметров, так же попробуйте применить к векторайзерам PCA для сокращения размерности посмотрите на качество сделайте выводы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combine_df.pickle', 'rb') as f:\n",
    "    combine_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love yoyou take with yoyou all the time ...</td>\n",
       "      <td>[model, love, yoyou, take, with, yoyou, all, t...</td>\n",
       "      <td>[model, love, yoyou, take, yoyou, time, yoyour]</td>\n",
       "      <td>[model, love, yoyou, take, yoyou, time, yoyour]</td>\n",
       "      <td>[model, love, yoyou, take, yoyou, time, yoyour]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory left right polarisation trump ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>[thought, factori, left, right, polaris, trump...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feel, like, mermaid, hairflip, neverreadi, fo...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hillary campaigned today in ohio omg amp used ...</td>\n",
       "      <td>[hillary, campaigned, today, in, ohio, omg, am...</td>\n",
       "      <td>[hillary, campaigned, today, ohio, omg, amp, u...</td>\n",
       "      <td>[hillari, campaign, today, ohio, omg, amp, use...</td>\n",
       "      <td>[hillary, campaigned, today, ohio, omg, amp, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "      <td>[happy, at, work, conference, right, mindset, ...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "      <td>[happi, work, confer, right, mindset, lead, cu...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my song so glad free download shoegaze newmusi...</td>\n",
       "      <td>[my, song, so, glad, free, download, shoegaze,...</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "      <td>[song, glad, free, download, shoegaz, newmus, ...</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1          2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  model love yoyou take with yoyou all the time ...   \n",
       "4          5    0.0                  factsguide society now motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory left right polarisation trump ...   \n",
       "49155  49156    NaN  feeling like mermaid hairflip neverready forma...   \n",
       "49156  49157    NaN  hillary campaigned today in ohio omg amp used ...   \n",
       "49157  49158    NaN  happy at work conference right mindset leads t...   \n",
       "49158  49159    NaN  my song so glad free download shoegaze newmusi...   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "0      [when, father, is, dysfunctional, and, is, so,...   \n",
       "1      [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                                [bihday, your, majesty]   \n",
       "3      [model, love, yoyou, take, with, yoyou, all, t...   \n",
       "4                 [factsguide, society, now, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, in, ohio, omg, am...   \n",
       "49157  [happy, at, work, conference, right, mindset, ...   \n",
       "49158  [my, song, so, glad, free, download, shoegaze,...   \n",
       "\n",
       "                                    tweet_token_filtered  \\\n",
       "0      [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1      [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                      [bihday, majesty]   \n",
       "3        [model, love, yoyou, take, yoyou, time, yoyour]   \n",
       "4                      [factsguide, society, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, ohio, omg, amp, u...   \n",
       "49157  [happy, work, conference, right, mindset, lead...   \n",
       "49158  [song, glad, free, download, shoegaze, newmusi...   \n",
       "\n",
       "                                           tweet_stemmed  \\\n",
       "0      [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1      [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                      [bihday, majesti]   \n",
       "3        [model, love, yoyou, take, yoyou, time, yoyour]   \n",
       "4                            [factsguid, societi, motiv]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factori, left, right, polaris, trump...   \n",
       "49155  [feel, like, mermaid, hairflip, neverreadi, fo...   \n",
       "49156  [hillari, campaign, today, ohio, omg, amp, use...   \n",
       "49157  [happi, work, confer, right, mindset, lead, cu...   \n",
       "49158  [song, glad, free, download, shoegaz, newmus, ...   \n",
       "\n",
       "                                        tweet_lemmatized  \n",
       "0      [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1      [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "2                                      [bihday, majesty]  \n",
       "3        [model, love, yoyou, take, yoyou, time, yoyour]  \n",
       "4                      [factsguide, society, motivation]  \n",
       "...                                                  ...  \n",
       "49154  [thought, factory, left, right, polarisation, ...  \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...  \n",
       "49156  [hillary, campaigned, today, ohio, omg, amp, u...  \n",
       "49157  [happy, work, conference, right, mindset, lead...  \n",
       "49158  [song, glad, free, download, shoegaze, newmusi...  \n",
       "\n",
       "[49159 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yoyour</th>\n",
       "      <th>yoyoy</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abl  absolut  accept  account  act  action  actor  actual  ad  adapt  \\\n",
       "0        0        0       0        0    0       0      0       0   0      0   \n",
       "1        0        0       0        0    0       0      0       0   0      0   \n",
       "2        0        0       0        0    0       0      0       0   0      0   \n",
       "3        0        0       0        0    0       0      0       0   0      0   \n",
       "4        0        0       0        0    0       0      0       0   0      0   \n",
       "...    ...      ...     ...      ...  ...     ...    ...     ...  ..    ...   \n",
       "49154    0        0       0        0    0       0      0       0   0      0   \n",
       "49155    0        0       0        0    0       0      0       0   0      0   \n",
       "49156    0        0       0        0    0       0      0       0   0      0   \n",
       "49157    0        0       0        0    0       0      0       0   0      0   \n",
       "49158    0        0       0        0    0       0      0       0   0      0   \n",
       "\n",
       "       ...  yo  yoga  york  young  youtub  yoyou  yoyour  yoyoy  yr  yummi  \n",
       "0      ...   0     0     0      0       0      0       0      0   0      0  \n",
       "1      ...   0     0     0      0       0      0       0      0   0      0  \n",
       "2      ...   0     0     0      0       0      0       0      0   0      0  \n",
       "3      ...   0     0     0      0       0      2       1      0   0      0  \n",
       "4      ...   0     0     0      0       0      0       0      0   0      0  \n",
       "...    ...  ..   ...   ...    ...     ...    ...     ...    ...  ..    ...  \n",
       "49154  ...   0     0     0      0       0      0       0      0   0      0  \n",
       "49155  ...   0     0     0      0       0      0       0      0   0      0  \n",
       "49156  ...   0     0     0      0       0      0       0      0   0      0  \n",
       "49157  ...   0     0     0      0       0      0       0      0   0      0  \n",
       "49158  ...   0     0     0      0       0      0       0      0   0      0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(max_df = 0.9, max_features = 1000, stop_words='english', preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "\n",
    "# Создаем the Bag-of-Words модель к 'tweet_stemmed'\n",
    "bow_tw_stemmed = count_vectorizer.fit_transform(combine_df.tweet_stemmed.tolist())\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bow_tw_stemmed.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yoyour</th>\n",
       "      <th>yoyoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able  absolutely  account  act  action  actor  actually  adapt  add  \\\n",
       "0         0           0        0    0       0      0         0      0    0   \n",
       "1         0           0        0    0       0      0         0      0    0   \n",
       "2         0           0        0    0       0      0         0      0    0   \n",
       "3         0           0        0    0       0      0         0      0    0   \n",
       "4         0           0        0    0       0      0         0      0    0   \n",
       "...     ...         ...      ...  ...     ...    ...       ...    ...  ...   \n",
       "49154     0           0        0    0       0      0         0      0    0   \n",
       "49155     0           0        0    0       0      0         0      0    0   \n",
       "49156     0           0        0    0       0      0         0      0    0   \n",
       "49157     0           0        0    0       0      0         0      0    0   \n",
       "49158     0           0        0    0       0      0         0      0    0   \n",
       "\n",
       "       adventure  ...  yo  yoga  york  young  youtube  yoyou  yoyour  yoyoyou  \\\n",
       "0              0  ...   0     0     0      0        0      0       0        0   \n",
       "1              0  ...   0     0     0      0        0      0       0        0   \n",
       "2              0  ...   0     0     0      0        0      0       0        0   \n",
       "3              0  ...   0     0     0      0        0      2       1        0   \n",
       "4              0  ...   0     0     0      0        0      0       0        0   \n",
       "...          ...  ...  ..   ...   ...    ...      ...    ...     ...      ...   \n",
       "49154          0  ...   0     0     0      0        0      0       0        0   \n",
       "49155          0  ...   0     0     0      0        0      0       0        0   \n",
       "49156          0  ...   0     0     0      0        0      0       0        0   \n",
       "49157          0  ...   0     0     0      0        0      0       0        0   \n",
       "49158          0  ...   0     0     0      0        0      0       0        0   \n",
       "\n",
       "       yr  yummy  \n",
       "0       0      0  \n",
       "1       0      0  \n",
       "2       0      0  \n",
       "3       0      0  \n",
       "4       0      0  \n",
       "...    ..    ...  \n",
       "49154   0      0  \n",
       "49155   0      0  \n",
       "49156   0      0  \n",
       "49157   0      0  \n",
       "49158   0      0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer2 = CountVectorizer(max_df = 0.9, max_features = 1000, stop_words='english', preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "\n",
    "# Создаем the Bag-of-Words модель к 'tweet_lemmatized'\n",
    "bow_tw_lemmatized = count_vectorizer2.fit_transform(combine_df.tweet_lemmatized.tolist())\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names2 = count_vectorizer2.get_feature_names()\n",
    "pd.DataFrame(bow_tw_lemmatized.toarray(), columns = feature_names2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно. Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df. Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000. Исключим стоп-слова с помощью stop_words='english'. Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yoyour</th>\n",
       "      <th>yoyoy</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744148</td>\n",
       "      <td>0.392399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abl  absolut  accept  account  act  action  actor  actual   ad  adapt  \\\n",
       "0      0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "1      0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "2      0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "3      0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "4      0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "...    ...      ...     ...      ...  ...     ...    ...     ...  ...    ...   \n",
       "49154  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "49155  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "49156  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "49157  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "49158  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "\n",
       "       ...   yo  yoga  york  young  youtub     yoyou    yoyour  yoyoy   yr  \\\n",
       "0      ...  0.0   0.0   0.0    0.0     0.0  0.000000  0.000000    0.0  0.0   \n",
       "1      ...  0.0   0.0   0.0    0.0     0.0  0.000000  0.000000    0.0  0.0   \n",
       "2      ...  0.0   0.0   0.0    0.0     0.0  0.000000  0.000000    0.0  0.0   \n",
       "3      ...  0.0   0.0   0.0    0.0     0.0  0.744148  0.392399    0.0  0.0   \n",
       "4      ...  0.0   0.0   0.0    0.0     0.0  0.000000  0.000000    0.0  0.0   \n",
       "...    ...  ...   ...   ...    ...     ...       ...       ...    ...  ...   \n",
       "49154  ...  0.0   0.0   0.0    0.0     0.0  0.000000  0.000000    0.0  0.0   \n",
       "49155  ...  0.0   0.0   0.0    0.0     0.0  0.000000  0.000000    0.0  0.0   \n",
       "49156  ...  0.0   0.0   0.0    0.0     0.0  0.000000  0.000000    0.0  0.0   \n",
       "49157  ...  0.0   0.0   0.0    0.0     0.0  0.000000  0.000000    0.0  0.0   \n",
       "49158  ...  0.0   0.0   0.0    0.0     0.0  0.000000  0.000000    0.0  0.0   \n",
       "\n",
       "       yummi  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "49154    0.0  \n",
       "49155    0.0  \n",
       "49156    0.0  \n",
       "49157    0.0  \n",
       "49158    0.0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.9, max_features = 1000, stop_words='english', preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "values_stemmed = tfidf_vectorizer.fit_transform(combine_df.tweet_stemmed.tolist())\n",
    "\n",
    "# Show the Model as a pandas DataFrame\n",
    "feature_names3 = tfidf_vectorizer.get_feature_names()\n",
    "pd.DataFrame(values_stemmed.toarray(), columns = feature_names3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yoyou</th>\n",
       "      <th>yoyour</th>\n",
       "      <th>yoyoyou</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.742113</td>\n",
       "      <td>0.39173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able  absolutely  account  act  action  actor  actually  adapt  add  \\\n",
       "0       0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "1       0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "2       0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "3       0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "4       0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "...     ...         ...      ...  ...     ...    ...       ...    ...  ...   \n",
       "49154   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "49155   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "49156   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "49157   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "49158   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "\n",
       "       adventure  ...   yo  yoga  york  young  youtube     yoyou   yoyour  \\\n",
       "0            0.0  ...  0.0   0.0   0.0    0.0      0.0  0.000000  0.00000   \n",
       "1            0.0  ...  0.0   0.0   0.0    0.0      0.0  0.000000  0.00000   \n",
       "2            0.0  ...  0.0   0.0   0.0    0.0      0.0  0.000000  0.00000   \n",
       "3            0.0  ...  0.0   0.0   0.0    0.0      0.0  0.742113  0.39173   \n",
       "4            0.0  ...  0.0   0.0   0.0    0.0      0.0  0.000000  0.00000   \n",
       "...          ...  ...  ...   ...   ...    ...      ...       ...      ...   \n",
       "49154        0.0  ...  0.0   0.0   0.0    0.0      0.0  0.000000  0.00000   \n",
       "49155        0.0  ...  0.0   0.0   0.0    0.0      0.0  0.000000  0.00000   \n",
       "49156        0.0  ...  0.0   0.0   0.0    0.0      0.0  0.000000  0.00000   \n",
       "49157        0.0  ...  0.0   0.0   0.0    0.0      0.0  0.000000  0.00000   \n",
       "49158        0.0  ...  0.0   0.0   0.0    0.0      0.0  0.000000  0.00000   \n",
       "\n",
       "       yoyoyou   yr  yummy  \n",
       "0          0.0  0.0    0.0  \n",
       "1          0.0  0.0    0.0  \n",
       "2          0.0  0.0    0.0  \n",
       "3          0.0  0.0    0.0  \n",
       "4          0.0  0.0    0.0  \n",
       "...        ...  ...    ...  \n",
       "49154      0.0  0.0    0.0  \n",
       "49155      0.0  0.0    0.0  \n",
       "49156      0.0  0.0    0.0  \n",
       "49157      0.0  0.0    0.0  \n",
       "49158      0.0  0.0    0.0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer2 = TfidfVectorizer(max_df = 0.9, max_features = 1000, stop_words='english', preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "values_lemmatized = tfidf_vectorizer2.fit_transform(combine_df.tweet_lemmatized.tolist())\n",
    "\n",
    "# Show the Model as a pandas DataFrame\n",
    "feature_names4 = tfidf_vectorizer2.get_feature_names()\n",
    "pd.DataFrame(values_lemmatized.toarray(), columns = feature_names4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре,\n",
    "\n",
    "составьте таблицу метод векторизации и скор который вы получили (в методах векторизации по изменяйте параметры что бы добиться лучшего скора)\n",
    "\n",
    "обратите внимание как падает/растёт скор при уменьшении количества фичей, и изменении параметров,\n",
    "\n",
    "так же попробуйте применить к векторайзерам PCA для сокращения размерности посмотрите на качество сделайте выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0  Stuning even for the non-gamer: This sound tra...  __label__2\n",
       "1  The best soundtrack ever to anything.: I'm rea...  __label__2\n",
       "2  Amazing!: This soundtrack is my favorite music...  __label__2\n",
       "3  Excellent Soundtrack: I truly like this soundt...  __label__2\n",
       "4  Remember, Pull Your Jaw Off The Floor After He...  __label__2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "data = open('corpus').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# создаем df\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels\n",
    "trainDF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "так как векторайзеры без токенизации - токенизирую corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['tweet_token'] = [nltk.tokenize.word_tokenize(str(x)) for x in trainDF['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "trainDF['text_stemmed']= [[stemmer.stem(word) for word in x] for x in trainDF['tweet_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['text_lemmatized']= [[lemmatizer.lemmatize(word) for word in x] for x in trainDF['tweet_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF.drop(['label'], axis=1), trainDF['label'])\n",
    "\n",
    "# labelEncode целевую переменную\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "# count_vect.fit(trainDF['text'])\n",
    "\n",
    "xtrain_count =  count_vectorizer.transform(train_x['text_stemmed'])\n",
    "xvalid_count =  count_vectorizer.transform(valid_x['text_stemmed'])\n",
    "\n",
    "classifier = linear_model.LogisticRegression(max_iter = 1000)\n",
    "classifier.fit(xtrain_count, train_y)\n",
    "predictions = classifier.predict(xvalid_count)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7944"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy1 = accuracy_score(valid_y, predictions)\n",
    "accuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__1    5097\n",
       "__label__2    4903\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results = {\n",
    "    'vectorizer': [],\n",
    "    'stem': [],\n",
    "    'max_df': [],\n",
    "    'max_feats': [],\n",
    "    'accuracy': []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['vectorizer'].append('Count_vectorizer')\n",
    "models_results['stem'].append('PorterStemmer')\n",
    "models_results['max_df'].append(0.9)\n",
    "models_results['max_feats'].append(1000)\n",
    "models_results['accuracy'].append(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7388"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count2 =  count_vectorizer2.transform(train_x['text_lemmatized'])\n",
    "xvalid_count2 =  count_vectorizer2.transform(valid_x['text_lemmatized'])\n",
    "    \n",
    "classifier2 = linear_model.LogisticRegression(max_iter = 1000)\n",
    "classifier2.fit(xtrain_count2, train_y)\n",
    "predictions2 = classifier2.predict(xvalid_count2)\n",
    "\n",
    "accuracy2 = accuracy_score(valid_y, predictions2)\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['vectorizer'].append('Count_vectorizer')\n",
    "models_results['stem'].append('WordNetLemmatizer')\n",
    "models_results['max_df'].append(0.9)\n",
    "models_results['max_feats'].append(1000)\n",
    "models_results['accuracy'].append(accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8164"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count3 =  tfidf_vectorizer.transform(train_x['text_stemmed'])\n",
    "xvalid_count3 =  tfidf_vectorizer.transform(valid_x['text_stemmed'])\n",
    "        \n",
    "classifier3 = linear_model.LogisticRegression(max_iter = 1000)\n",
    "classifier3.fit(xtrain_count3, train_y)\n",
    "predictions3 = classifier3.predict(xvalid_count3)\n",
    "\n",
    "accuracy3 = accuracy_score(valid_y, predictions3)\n",
    "accuracy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['vectorizer'].append('TFIDF_vectorizer')\n",
    "models_results['stem'].append('PorterStemmer')\n",
    "models_results['max_df'].append(0.9)\n",
    "models_results['max_feats'].append(1000)\n",
    "models_results['accuracy'].append(accuracy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7556"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count4 =  tfidf_vectorizer2.transform(train_x['text_lemmatized'])\n",
    "xvalid_count4 =  tfidf_vectorizer2.transform(valid_x['text_lemmatized'])\n",
    "        \n",
    "classifier4 = linear_model.LogisticRegression(max_iter = 1000)\n",
    "classifier4.fit(xtrain_count4, train_y)\n",
    "predictions4 = classifier4.predict(xvalid_count4)\n",
    "\n",
    "accuracy4 = accuracy_score(valid_y, predictions4)\n",
    "accuracy4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['vectorizer'].append('TFIDF_vectorizer')\n",
    "models_results['stem'].append('WordNetLemmatizer')\n",
    "models_results['max_df'].append(0.9)\n",
    "models_results['max_feats'].append(1000)\n",
    "models_results['accuracy'].append(accuracy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>stem</th>\n",
       "      <th>max_df</th>\n",
       "      <th>max_feats</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.8164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         vectorizer               stem  max_df  max_feats  accuracy\n",
       "2  TFIDF_vectorizer      PorterStemmer     0.9       1000    0.8164\n",
       "0  Count_vectorizer      PorterStemmer     0.9       1000    0.7944\n",
       "3  TFIDF_vectorizer  WordNetLemmatizer     0.9       1000    0.7556\n",
       "1  Count_vectorizer  WordNetLemmatizer     0.9       1000    0.7388"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=models_results).sort_values('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvTF (max_df = 0.9, max_features = 1000):\n",
    "    #TFIDF lemmatized\n",
    "    vectorizer = TfidfVectorizer(max_df = max_df, max_features = max_features, stop_words='english', preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "    vectorizer.fit_transform(combine_df.tweet_lemmatized.tolist())\n",
    "    \n",
    "    xtrain_count =  vectorizer.transform(train_x['text_lemmatized'])\n",
    "    xvalid_count =  vectorizer.transform(valid_x['text_lemmatized'])\n",
    "\n",
    "    classifier = linear_model.LogisticRegression(max_iter = 1000)\n",
    "    classifier.fit(xtrain_count, train_y)\n",
    "    predictions = classifier.predict(xvalid_count)\n",
    "\n",
    "    accuracy = accuracy_score(valid_y, predictions)\n",
    "    \n",
    "    models_results['vectorizer'].append('TFIDF_vectorizer')\n",
    "    models_results['stem'].append('WordNetLemmatizer')\n",
    "    models_results['max_df'].append(max_df)\n",
    "    models_results['max_feats'].append(max_features)\n",
    "    models_results['accuracy'].append(accuracy)\n",
    "    #TFIDF stemmed\n",
    "    vectorizer = TfidfVectorizer(max_df = max_df, max_features = max_features, stop_words='english', preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "    vectorizer.fit_transform(combine_df.tweet_stemmed.tolist())\n",
    "    \n",
    "    xtrain_count =  vectorizer.transform(train_x['text_stemmed'])\n",
    "    xvalid_count =  vectorizer.transform(valid_x['text_stemmed'])\n",
    "\n",
    "    classifier = linear_model.LogisticRegression(max_iter = 1000)\n",
    "    classifier.fit(xtrain_count, train_y)\n",
    "    predictions = classifier.predict(xvalid_count)\n",
    "\n",
    "    accuracy = accuracy_score(valid_y, predictions)\n",
    "    \n",
    "    models_results['vectorizer'].append('TFIDF_vectorizer')\n",
    "    models_results['stem'].append('PorterStemmer')\n",
    "    models_results['max_df'].append(max_df)\n",
    "    models_results['max_feats'].append(max_features)  \n",
    "    models_results['accuracy'].append(accuracy)\n",
    "\n",
    "    #Count lemmatized\n",
    "    vectorizer = CountVectorizer(max_df = max_df, max_features = max_features, stop_words='english', preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "    vectorizer.fit_transform(combine_df.tweet_lemmatized.tolist())\n",
    "    \n",
    "    xtrain_count =  vectorizer.transform(train_x['text_lemmatized'])\n",
    "    xvalid_count =  vectorizer.transform(valid_x['text_lemmatized'])\n",
    "\n",
    "    classifier = linear_model.LogisticRegression(max_iter = 1000)\n",
    "    classifier.fit(xtrain_count, train_y)\n",
    "    predictions = classifier.predict(xvalid_count)\n",
    "\n",
    "    accuracy = accuracy_score(valid_y, predictions)\n",
    "    \n",
    "    models_results['vectorizer'].append('Count_vectorizer')\n",
    "    models_results['stem'].append('WordNetLemmatizer')\n",
    "    models_results['max_df'].append(max_df)\n",
    "    models_results['max_feats'].append(max_features)\n",
    "    models_results['accuracy'].append(accuracy)\n",
    "    #Count stemmed\n",
    "    vectorizer = CountVectorizer(max_df = max_df, max_features = max_features, stop_words='english', preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "    vectorizer.fit_transform(combine_df.tweet_stemmed.tolist())\n",
    "    \n",
    "    xtrain_count =  vectorizer.transform(train_x['text_stemmed'])\n",
    "    xvalid_count =  vectorizer.transform(valid_x['text_stemmed'])\n",
    "\n",
    "    classifier = linear_model.LogisticRegression(max_iter = 1000)\n",
    "    classifier.fit(xtrain_count, train_y)\n",
    "    predictions = classifier.predict(xvalid_count)\n",
    "\n",
    "    accuracy = accuracy_score(valid_y, predictions4)\n",
    "    \n",
    "    models_results['vectorizer'].append('Count_vectorizer')\n",
    "    models_results['stem'].append('PorterStemmer')\n",
    "    models_results['max_df'].append(max_df)\n",
    "    models_results['max_feats'].append(max_features)\n",
    "    models_results['accuracy'].append(accuracy)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"обнулим\" результаты, пересчитаем все варианты\n",
    "\n",
    "models_results = {\n",
    "    'vectorizer': [],\n",
    "    'stem': [],\n",
    "    'max_df': [],\n",
    "    'max_feats': [],\n",
    "    'accuracy': []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for max_df in [0.5, 0.7,  0.9]:\n",
    "    for max_features in [500, 1000, 5000, 10000, 20000]:\n",
    "        crossvTF(max_df, max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>stem</th>\n",
       "      <th>max_df</th>\n",
       "      <th>max_feats</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.8476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.8476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.8476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.8164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.8164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.8164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.7968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.7968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.7968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.7960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.7960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.7960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>500</td>\n",
       "      <td>0.6996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>0.6996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Count_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.6996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vectorizer               stem  max_df  max_feats  accuracy\n",
       "29  TFIDF_vectorizer      PorterStemmer     0.7       5000    0.8476\n",
       "49  TFIDF_vectorizer      PorterStemmer     0.9       5000    0.8476\n",
       "9   TFIDF_vectorizer      PorterStemmer     0.5       5000    0.8476\n",
       "13  TFIDF_vectorizer      PorterStemmer     0.5      10000    0.8460\n",
       "33  TFIDF_vectorizer      PorterStemmer     0.7      10000    0.8460\n",
       "53  TFIDF_vectorizer      PorterStemmer     0.9      10000    0.8460\n",
       "57  TFIDF_vectorizer      PorterStemmer     0.9      20000    0.8440\n",
       "37  TFIDF_vectorizer      PorterStemmer     0.7      20000    0.8440\n",
       "17  TFIDF_vectorizer      PorterStemmer     0.5      20000    0.8440\n",
       "16  TFIDF_vectorizer  WordNetLemmatizer     0.5      20000    0.8180\n",
       "56  TFIDF_vectorizer  WordNetLemmatizer     0.9      20000    0.8180\n",
       "36  TFIDF_vectorizer  WordNetLemmatizer     0.7      20000    0.8180\n",
       "25  TFIDF_vectorizer      PorterStemmer     0.7       1000    0.8164\n",
       "45  TFIDF_vectorizer      PorterStemmer     0.9       1000    0.8164\n",
       "5   TFIDF_vectorizer      PorterStemmer     0.5       1000    0.8164\n",
       "52  TFIDF_vectorizer  WordNetLemmatizer     0.9      10000    0.8104\n",
       "12  TFIDF_vectorizer  WordNetLemmatizer     0.5      10000    0.8104\n",
       "32  TFIDF_vectorizer  WordNetLemmatizer     0.7      10000    0.8104\n",
       "28  TFIDF_vectorizer  WordNetLemmatizer     0.7       5000    0.7984\n",
       "8   TFIDF_vectorizer  WordNetLemmatizer     0.5       5000    0.7984\n",
       "48  TFIDF_vectorizer  WordNetLemmatizer     0.9       5000    0.7984\n",
       "18  Count_vectorizer  WordNetLemmatizer     0.5      20000    0.7968\n",
       "58  Count_vectorizer  WordNetLemmatizer     0.9      20000    0.7968\n",
       "38  Count_vectorizer  WordNetLemmatizer     0.7      20000    0.7968\n",
       "14  Count_vectorizer  WordNetLemmatizer     0.5      10000    0.7960\n",
       "34  Count_vectorizer  WordNetLemmatizer     0.7      10000    0.7960\n",
       "54  Count_vectorizer  WordNetLemmatizer     0.9      10000    0.7960\n",
       "30  Count_vectorizer  WordNetLemmatizer     0.7       5000    0.7816\n",
       "50  Count_vectorizer  WordNetLemmatizer     0.9       5000    0.7816\n",
       "10  Count_vectorizer  WordNetLemmatizer     0.5       5000    0.7816\n",
       "1   TFIDF_vectorizer      PorterStemmer     0.5        500    0.7660\n",
       "21  TFIDF_vectorizer      PorterStemmer     0.7        500    0.7660\n",
       "41  TFIDF_vectorizer      PorterStemmer     0.9        500    0.7660\n",
       "44  TFIDF_vectorizer  WordNetLemmatizer     0.9       1000    0.7556\n",
       "47  Count_vectorizer      PorterStemmer     0.9       1000    0.7556\n",
       "43  Count_vectorizer      PorterStemmer     0.9        500    0.7556\n",
       "39  Count_vectorizer      PorterStemmer     0.7      20000    0.7556\n",
       "55  Count_vectorizer      PorterStemmer     0.9      10000    0.7556\n",
       "51  Count_vectorizer      PorterStemmer     0.9       5000    0.7556\n",
       "59  Count_vectorizer      PorterStemmer     0.9      20000    0.7556\n",
       "3   Count_vectorizer      PorterStemmer     0.5        500    0.7556\n",
       "31  Count_vectorizer      PorterStemmer     0.7       5000    0.7556\n",
       "27  Count_vectorizer      PorterStemmer     0.7       1000    0.7556\n",
       "24  TFIDF_vectorizer  WordNetLemmatizer     0.7       1000    0.7556\n",
       "23  Count_vectorizer      PorterStemmer     0.7        500    0.7556\n",
       "4   TFIDF_vectorizer  WordNetLemmatizer     0.5       1000    0.7556\n",
       "35  Count_vectorizer      PorterStemmer     0.7      10000    0.7556\n",
       "19  Count_vectorizer      PorterStemmer     0.5      20000    0.7556\n",
       "15  Count_vectorizer      PorterStemmer     0.5      10000    0.7556\n",
       "11  Count_vectorizer      PorterStemmer     0.5       5000    0.7556\n",
       "7   Count_vectorizer      PorterStemmer     0.5       1000    0.7556\n",
       "6   Count_vectorizer  WordNetLemmatizer     0.5       1000    0.7388\n",
       "26  Count_vectorizer  WordNetLemmatizer     0.7       1000    0.7388\n",
       "46  Count_vectorizer  WordNetLemmatizer     0.9       1000    0.7388\n",
       "40  TFIDF_vectorizer  WordNetLemmatizer     0.9        500    0.7120\n",
       "20  TFIDF_vectorizer  WordNetLemmatizer     0.7        500    0.7120\n",
       "0   TFIDF_vectorizer  WordNetLemmatizer     0.5        500    0.7120\n",
       "22  Count_vectorizer  WordNetLemmatizer     0.7        500    0.6996\n",
       "42  Count_vectorizer  WordNetLemmatizer     0.9        500    0.6996\n",
       "2   Count_vectorizer  WordNetLemmatizer     0.5        500    0.6996"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_results = pd.DataFrame(data=models_results)\n",
    "df_models_results.sort_values('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_results['vect&stem'] = df_models_results['vectorizer'] +'&' + df_models_results['stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65, 0.85)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 665.225x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_models_results, kind=\"bar\",\n",
    "    x=\"max_feats\", y=\"accuracy\", hue=\"vect&stem\",\n",
    "    ci=\"sd\", palette=\"dark\", alpha=.6, height=6\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"accuracy\")\n",
    "g.legend.set_title(\"\")\n",
    "plt.ylim(0.65,0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы: Наилучший результат дает сочетание TFIDF_vectorizer&PorterStemmer, при этом увеличение количества фичей улучшает метрику (кроме комбинации Count_vectorizer и PorterStemmer, здесь зависимости от max_features практически нет). Также при использовании сочетания TFIDF_vectorizer&PorterStemmer увеличение кол-ва фичей дает эффект до определенного предела (более 5000 уже не дает прироста качества)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65, 0.85)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 665.225x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_models_results, kind=\"bar\",\n",
    "    x=\"max_df\", y=\"accuracy\", hue=\"vect&stem\",\n",
    "    ci=\"sd\", palette=\"dark\", alpha=.6, height=6\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"accuracy\")\n",
    "g.legend.set_title(\"\")\n",
    "plt.ylim(0.65,0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы: Здесь также видно, что наилучший результат дает сочетание TFIDF_vectorizer&PorterStemmer, при этом изменение max_df почти не влияет на метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим к лучшей конфигурации векторайзера PCA для сокращения размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMAXL\\Anaconda3\\envs\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pca = TruncatedSVD(n_components = 7500)\n",
    "#TFIDF stemmed\n",
    "max_df = 0.5\n",
    "max_features = 20000\n",
    "vectorizer = TfidfVectorizer(max_df = max_df, max_features = max_features, stop_words='english', preprocessor=lambda x: x, tokenizer=lambda x: x)\n",
    "vectorizer.fit_transform(combine_df.tweet_stemmed.tolist())\n",
    "\n",
    "xtrain_count =  vectorizer.transform(train_x['text_stemmed'])\n",
    "xvalid_count =  vectorizer.transform(valid_x['text_stemmed'])\n",
    "\n",
    "xtrain_count = pca.fit_transform(xtrain_count)\n",
    "xvalid_count = pca.transform(xvalid_count)\n",
    "\n",
    "classifier = linear_model.LogisticRegression(max_iter = 1000)\n",
    "classifier.fit(xtrain_count, train_y)\n",
    "predictions = classifier.predict(xvalid_count)\n",
    "\n",
    "accuracy = accuracy_score(valid_y, predictions)\n",
    "\n",
    "models_results['vectorizer'].append('TFIDF_vectorizer SVD')\n",
    "models_results['stem'].append('PorterStemmer')\n",
    "models_results['max_df'].append(max_df)\n",
    "models_results['max_feats'].append(max_features)  \n",
    "models_results['accuracy'].append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>stem</th>\n",
       "      <th>max_df</th>\n",
       "      <th>max_feats</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.8476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.8476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.8476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>TFIDF_vectorizer SVD</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.8164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.8164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.8164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>PorterStemmer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDF_vectorizer</td>\n",
       "      <td>WordNetLemmatizer</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              vectorizer               stem  max_df  max_feats  accuracy\n",
       "29      TFIDF_vectorizer      PorterStemmer     0.7       5000    0.8476\n",
       "49      TFIDF_vectorizer      PorterStemmer     0.9       5000    0.8476\n",
       "9       TFIDF_vectorizer      PorterStemmer     0.5       5000    0.8476\n",
       "53      TFIDF_vectorizer      PorterStemmer     0.9      10000    0.8460\n",
       "13      TFIDF_vectorizer      PorterStemmer     0.5      10000    0.8460\n",
       "33      TFIDF_vectorizer      PorterStemmer     0.7      10000    0.8460\n",
       "17      TFIDF_vectorizer      PorterStemmer     0.5      20000    0.8440\n",
       "57      TFIDF_vectorizer      PorterStemmer     0.9      20000    0.8440\n",
       "37      TFIDF_vectorizer      PorterStemmer     0.7      20000    0.8440\n",
       "60  TFIDF_vectorizer SVD      PorterStemmer     0.5      20000    0.8440\n",
       "56      TFIDF_vectorizer  WordNetLemmatizer     0.9      20000    0.8180\n",
       "16      TFIDF_vectorizer  WordNetLemmatizer     0.5      20000    0.8180\n",
       "36      TFIDF_vectorizer  WordNetLemmatizer     0.7      20000    0.8180\n",
       "5       TFIDF_vectorizer      PorterStemmer     0.5       1000    0.8164\n",
       "25      TFIDF_vectorizer      PorterStemmer     0.7       1000    0.8164\n",
       "45      TFIDF_vectorizer      PorterStemmer     0.9       1000    0.8164\n",
       "52      TFIDF_vectorizer  WordNetLemmatizer     0.9      10000    0.8104\n",
       "12      TFIDF_vectorizer  WordNetLemmatizer     0.5      10000    0.8104\n",
       "32      TFIDF_vectorizer  WordNetLemmatizer     0.7      10000    0.8104\n",
       "48      TFIDF_vectorizer  WordNetLemmatizer     0.9       5000    0.7984\n",
       "8       TFIDF_vectorizer  WordNetLemmatizer     0.5       5000    0.7984\n",
       "28      TFIDF_vectorizer  WordNetLemmatizer     0.7       5000    0.7984\n",
       "21      TFIDF_vectorizer      PorterStemmer     0.7        500    0.7660\n",
       "41      TFIDF_vectorizer      PorterStemmer     0.9        500    0.7660\n",
       "1       TFIDF_vectorizer      PorterStemmer     0.5        500    0.7660\n",
       "4       TFIDF_vectorizer  WordNetLemmatizer     0.5       1000    0.7556\n",
       "44      TFIDF_vectorizer  WordNetLemmatizer     0.9       1000    0.7556\n",
       "24      TFIDF_vectorizer  WordNetLemmatizer     0.7       1000    0.7556\n",
       "20      TFIDF_vectorizer  WordNetLemmatizer     0.7        500    0.7120\n",
       "40      TFIDF_vectorizer  WordNetLemmatizer     0.9        500    0.7120\n",
       "0       TFIDF_vectorizer  WordNetLemmatizer     0.5        500    0.7120"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_results = pd.DataFrame(data=models_results)\n",
    "df_models_results.loc[df_models_results['vectorizer'].isin(['TFIDF_vectorizer', 'TFIDF_vectorizer SVD'])].sort_values('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод - результат применения модели с PCA такой же как и без него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
